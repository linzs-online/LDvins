%YAML:1.0

#common parameters
#support: 1 imu 1 cam; 1 imu 2 cam: 2 cam; 
imu: 1         
num_of_cam: 2  

imu_topic: "/t265/imu0"
image0_topic: "/t265/fisheye1/image_raw"
image1_topic: "/t265/fisheye2/image_raw"
output_path: "/home/linzs/vinsOutput/"

cam0_calib: "left.yaml"
cam1_calib: "right.yaml"
image_width: 848
image_height: 800
   

# Extrinsic parameter between IMU and Camera.
estimate_extrinsic: 0   # 0  Have an accurate extrinsic parameters. We will trust the following imu^R_cam, imu^T_cam, don't change it.
                        # 1  Have an initial guess about extrinsic parameters. We will optimize around your initial guess.

body_T_cam0: !!opencv-matrix
   rows: 4
   cols: 4
   dt: d
   data: [-9.9864783659251311e-01, 1.5860421374056650e-02, 4.9507024783675128e-02, 0.005754793009546214,
          -1.5846775818903824e-02, -9.9987420872732002e-01, 6.6814523992203881e-04, 0.004283178521816982,
          4.9511394297065213e-02, -1.1728492483008577e-04, 9.9877355195209638e-01, -0.005638553131443425,
          0., 0., 0., 1.]
   # data: [-0.9996934517722752, -0.017627605360341365, 0.017385914209325233, 0.005754793009546214,
   #          0.01763901821691402, -0.999844293739213, 0.0005033025707699151, 0.004283178521816982,
   #          0.017374335094538958, 0.0008098187417148282, 0.999848726895038, -0.005638553131443425,
   #          0., 0., 0., 1.]
   # data: [-0.999926, -0.999926, 0.0111033, 0.0106992,
   #       0.00493413, -0.999984, 0.00269461, -5.27951e-05,
   #       0.0110899, 0.0027492, 0.999935, -0.000118662,
   #       0., 0., 0., 1.]

body_T_cam1: !!opencv-matrix
   rows: 4
   cols: 4
   dt: d
   data: [-9.9908533290785595e-01, 1.6035957654161839e-02, 3.9640202200716325e-02, -0.06100400373236911,
         -1.5489640954704493e-02, -9.9978129877729116e-01, 1.4050823402495322e-02, 0.004859511023863885,
         3.9856851249115109e-02, 1.3423959077250542e-02, 9.9911522295038535e-01, -0.0022157241622004077,
         0., 0., 0., 1. ]
   # data: [-0.999768258980969, -0.01371448358867344, 0.016593410561375914, -0.06100400373236911,
   #              0.013686981433494675, -0.9999047625489491, -0.001769850606391636, 0.004859511023863885,
   #              0.016616102834345566, -0.0015423267571366712, 0.9998607534825902, -0.0022157241622004077,
   #              0., 0., 0., 1. ]
   # data: [-0.999978, 0.00457962, 0.00473468, -0.0533793,
   #        -0.00454895, -0.999969, 0.00646823, -0.000372384,
   #        0.00476415, 0.00644655, 0.999968, -1.49855e-05,
   #        0., 0., 0., 1. ]

#Multiple thread support
multiple_thread: 1

#feature traker paprameters
max_cnt: 200            # max feature number in feature tracking
min_dist: 20            # min distance between two features 
freq: 10                # frequence (Hz) of publish tracking result. At least 10Hz for good estimation. If set 0, the frequence will be same as raw image 
F_threshold: 1.0        # ransac threshold (pixel)
show_track: 1           # publish tracking image as topic
flow_back: 1            # perform forward and backward optical flow to improve feature tracking accuracy

#optimization parameters
max_solver_time: 0.08  # max solver itration time (ms), to guarantee real time
max_num_iterations: 8   # max solver itrations, to guarantee real time
keyframe_parallax: 10.0 # keyframe selection threshold (pixel)

#imu parameters       The more accurate parameters you provide, the better performance
acc_n: 1.09387e-02          # accelerometer measurement noise standard deviation. #0.2   0.04
gyr_n: 1.8491e-03         # gyroscope measurement noise standard deviation.     #0.05  0.004
acc_w: 5.8973e-04         # accelerometer bias random work noise standard deviation.  #0.002
gyr_w: 2.5482e-05       # gyroscope bias random work noise standard deviation.     #4.0e-5
g_norm: 9.805         # gravity magnitude

#unsynchronization parameters
estimate_td: 1                      # online estimate time offset between camera and imu
td: 0.00                             # initial value of time offset. unit: s. readed image clock + td = real image clock (IMU clock)

#loop closure parameters
load_previous_pose_graph: 0        # load and reuse previous pose graph; load from 'pose_graph_save_path'
pose_graph_save_path: "/home/linzs/vinsOutput/pose_graph/" # save and load path
save_image: 0                   # save image in pose graph for visualization prupose; you can close this function by setting 0 

# 通过topic保存真值
save_groundTruth: 0
ground_truth_save_path: "/home/linzs/vinsOutput/ground_truth.csv"
